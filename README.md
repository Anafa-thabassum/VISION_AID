
# VisionAid

VisionAid is a **mobile application** designed to assist **visually impaired, low-vision individuals, and elderly users with reading difficulties** by identifying objects *and* reading text aloud in real time. With VisionAid, users can navigate their surroundings more confidently and independently.

---

## ğŸš€ Features

- ğŸ“· **Real-Time Object Recognition**  
  Detects objects using the device camera and provides audio feedback.

- ğŸ”¡ **Text Recognition (OCR)**  
  Reads text from the environment (e.g., signs, books) aloud to the user.

- ğŸ—£ï¸ **Audio Output**  
  Converts visual input into spoken words for enhanced accessibility.

- ğŸ“± **Mobile-First Interface**  
  Built to run smoothly on smartphone platforms.

---

## ğŸ§  How It Works

VisionAid captures frames from the phone camera and sends them through intelligent visual processing algorithms. The app then identifies objects and text present in the camera view and provides **voice-based feedback**, enabling users to:

- Navigate their surroundings
- Recognize objects
- Read printed text

This helps visually challenged users perform daily tasks more independently and confidently.

---

## ğŸ›  Tech Stack

| Component | Technology |
|-----------|------------|
| App Framework | React Native / JavaScript |
| Computer Vision | OCR libraries / ML models |
| Audio Output | Text-to-Speech APIs |
| Platform | Mobile (Android / iOS) |

*(Modify based on real implementation if needed)*

---

## ğŸ“ Project Structure

```

VISION_AID/
â”œâ”€â”€ app/                  # Main app code
â”œâ”€â”€ App.js                # App entry point
â”œâ”€â”€ index.js              # App startup file
â”œâ”€â”€ app.json              # App config
â”œâ”€â”€ package.json          # NPM dependencies
â””â”€â”€ README.md             # Project documentation

````

---

## ğŸ”§ Getting Started

### Prerequisites

Before you begin, make sure you have:

- Node.js and npm installed
- React Native CLI (if running on device/emulator)
- Android Studio / Xcode for emulators

---

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/Anafa-thabassum/VISION_AID.git
   cd VISION_AID
````

2. **Install dependencies**

   ```bash
   npm install
   ```

3. **Run on Android**

   ```bash
   npx react-native run-android
   ```

4. **Run on iOS**

   ```bash
   npx react-native run-ios
   ```

---

## ğŸ§ª How to Use

1. Grant camera and audio permissions.
2. Point the camera at your environment.
3. The app will detect objects and text.
4. Audio feedback will describe the scene or text.

*(Include screenshots or a demo video if available)*

---

## â¤ï¸ Contributing

Contributions are welcome! If you want to add features or improve VisionAid:

1. Fork the repo
2. Create a new branch
3. Make your changes
4. Submit a Pull Request

---



## ğŸ™Œ Acknowledgements

Thanks to all contributors and users supporting VisionAid in making technology more accessible to everyone.

---
âœ¨ Author
Made with â¤ï¸
 by Anafa
https://www.linkedin.com/in/anafa-thabassum-052520326/
---


